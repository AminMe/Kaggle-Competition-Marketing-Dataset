{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code by Amin MESSAOUDI - Master Data & Knowledge\n",
    "# Kaggle competition: data-marketing\n",
    "## Leaderboard name: Amin | score: 0.58940"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's go !\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's go !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Predict for a portugues bank if these profile will subscribe or not.\n",
    "https://www.kaggle.com/c/data-marketing\n",
    " \n",
    "## kappa\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html\n",
    "\n",
    "## matthews\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Preprocess part is very import for learning part.\n",
    "Here the goal is to normalize data into number. Pre-process done in training should also be done in test set also.\n",
    "There is two way to pre-process in this code.\n",
    "First one is by doing dummies, meaning transforming \"a\", \"b\", \"c\" values as bits here of size 3: 001, 010, 100 for each value.</br>\n",
    "\n",
    "</br>\n",
    "The problem here, we have unbalanced data, we have approximately 300 yes over 2700 no y values.\n",
    "We will discuss about that in explaination of classifier part\n",
    "</br>\n",
    "\n",
    "</br>\n",
    "Hypothesis tried : </br>\n",
    "In the code below I tried to do some oversampling by duplicating yes rows (duplicated from 1 to 10) but no better result found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size :  (2999, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2999, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pand\n",
    "import numpy as np\n",
    "\n",
    "# allow to display all columns\n",
    "pand.set_option('display.max_columns', None)\n",
    "\n",
    "# loading the training set\n",
    "dataset = pand.read_csv(\"./data/train.csv\", delimiter=\";\", header=0)\n",
    "# renaming it\n",
    "trainset = dataset\n",
    "\n",
    "print(\"size : \",trainset.shape)\n",
    "\n",
    "# Tentative of Oversampling by duplicating yes\n",
    "#is_yes = trainset['y'] == 'yes'\n",
    "#df_try = trainset[is_yes]\n",
    "#trainset = trainset.append([df_try],ignore_index='no')\n",
    "#trainset = trainset.append([df_try],ignore_index='no')\n",
    "#trainset = trainset.append([df_try],ignore_index='no')\n",
    "\n",
    "# Tentative of removing a value\n",
    "#trainset = trainset[trainset['poutcome'] != 'nonexistent']\n",
    "\n",
    "trainset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just making a copy of trainset\n",
    "oldtrain = pand.read_csv(\"./data/train.csv\", delimiter=\";\", header=0)\n",
    "oldtrain.loc[oldtrain['y'] == 'yes', 'y'] = '1'\n",
    "oldtrain.loc[oldtrain['y'] == 'no', 'y'] = '0'\n",
    "#trainset.map({'yes': 1, 'no': 0})\n",
    "oldtrain.y = oldtrain.y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>487</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.313</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital education default housing loan   contact month  \\\n",
       "0   30  blue-collar  married  basic.9y      no     yes   no  cellular   may   \n",
       "\n",
       "  day_of_week  duration  campaign  pdays  previous     poutcome  emp.var.rate  \\\n",
       "0         fri       487         2    999         0  nonexistent          -1.8   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          92.893          -46.2      1.313       5099.1  no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename colums of testset according to trainset\n",
    "Since headers are different a renaming of columns is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size :  (1120, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>management</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>thu</td>\n",
       "      <td>144</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         job   marital          education default housing loan  \\\n",
       "0   49  management  divorced  university.degree      no      no   no   \n",
       "\n",
       "    contact month day_of_week  duration  campaign  pdays  previous  \\\n",
       "0  cellular   jul         thu       144         5    999         0   \n",
       "\n",
       "      poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0  nonexistent           1.4          93.918          -42.7      4.963   \n",
       "\n",
       "   nr.employed  \n",
       "0       5228.1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = pand.read_csv(\"./data/test.csv\", delimiter=\";\", header=None)\n",
    "\n",
    "i = 0\n",
    "for col in testset.columns:\n",
    "    testset = testset.rename(columns={testset.columns[i]: trainset.columns[i]})\n",
    "    i = i+1\n",
    "\n",
    "print(\"size : \",testset.shape)\n",
    "testset.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling tentative\n",
    "Hypothesis: </br>\n",
    "\n",
    "If we remove some rows useless, for example in pdays = 1, 2,  9, 11, 16 we don't have enough data to decide yes or no so it's seems to be better to remove them.\n",
    "But here the result was not changing anything to the result output.\n",
    "\n",
    "So the code below is commented, but could be used in future for improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepre_process(df):\n",
    "    df['poutcome'] = df['poutcome'].replace(['nonexistent'],'failure')\n",
    "    return df\n",
    "    \n",
    "def undersampling(df):\n",
    "    df = df[(df.pdays != 1) & (df.y != 1)]\n",
    "    df = df[(df.pdays != 2) & (df.y != 1)]\n",
    "    df = df[(df.pdays != 9) & (df.y != 1)]\n",
    "    df = df[(df.pdays != 11) & (df.y != 1)]\n",
    "    df = df[(df.pdays != 16) & (df.y != 1)]\n",
    "    return df\n",
    "\n",
    "#trainset = prepre_process(trainset)\n",
    "#trainset = undersampling(trainset)\n",
    "#testset = prepre_process(testset)\n",
    "#testset.pdays.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete features func\n",
    "\n",
    "Once we have loaded data, the goal is not learn on all the features (columns) we have.\n",
    "But to found the more relevants, ones. The ones that are going to make a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete columns useless, in a given df\n",
    "def deleteColumns(featureToIgnore, df):\n",
    "    for feature in featureToIgnore:\n",
    "        if feature in df.columns:\n",
    "            del df[feature]            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unicity of colum education need to be treated\n",
      "['basic.9y' 'high.school' 'university.degree' 'professional.course'\n",
      " 'basic.6y' 'basic.4y' 'unknown']\n",
      "['university.degree' 'high.school' 'basic.9y' 'professional.course'\n",
      " 'unknown' 'basic.4y' 'basic.6y' 'illiterate']\n",
      "\n",
      "\n",
      "Unicity of colum default need to be treated\n",
      "['no' 'unknown']\n",
      "['no' 'unknown' 'yes']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if values in both dataset are the same, for instance if \n",
    "# there is more values in testset this method is going to show it \n",
    "# Unicity of colum default need to be treated\n",
    "# ['no' 'unknown']\n",
    "# ['no' 'unknown' 'yes']\n",
    "# means that we have yes values in default column, that could also be translated as \n",
    "# \"we should not learn on this\" column because we don't know what to do when we have yes\n",
    "def checkUnique(train, test):\n",
    "    for column in test.columns:\n",
    "        if test[column].dtype!='int64' and test[column].dtype!='float64':\n",
    "            if len(train[column].unique()) != len(test[column].unique()):\n",
    "                print('Unicity of colum ' + column + ' need to be treated')\n",
    "                print(trainset[column].unique())\n",
    "                print(testset[column].unique())\n",
    "                print('\\n')\n",
    "\n",
    "                \n",
    "checkUnique(trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First preprocess, change values of y yes by 1 and no by 0\n",
    "# process y\n",
    "trainset.loc[trainset['y'] == 'yes', 'y'] = '1'\n",
    "trainset.loc[trainset['y'] == 'no', 'y'] = '0'\n",
    "#trainset.map({'yes': 1, 'no': 0})\n",
    "trainset.y = trainset.y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEXCAYAAACqIS9uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116d4c710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEtCAYAAAAPwAulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSY0x+CWpMQa/JDXG4JekxvxfCPdXEgHgPC8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112d6ee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pyp\n",
    "\n",
    "\n",
    "# Here are the features we are going to ignore in the learning part\n",
    "# How did I decide this ?\n",
    "# 1 - By showing plot of these columns compared to y values. If we take a look to day_of_week plot\n",
    "# we can notice that the mean value for each of these day is under 0.13 meaning we can not decide\n",
    "# with this column if it should be yes or no, this is going to tend to answer more \"no\" that yes\n",
    "# since we have 0.13% of chance to be yes\n",
    "# Same reasoning for loan columns and so on\n",
    "# 2 - Even showing plot does not always help, for euribor3m nr.employed and cons.price.idx\n",
    "# variation is to high to decide, so the solution was to tries them one by one and together to see\n",
    "# impact in the prediction, but these 3 where not good for my predictions (smaller kappa and matthew)\n",
    "featureToIgnore = ['campaign', 'day_of_week', 'education',\n",
    "                   'cons.price.idx','euribor3m','nr.employed','default','housing',\n",
    "                   'loan', 'marital','job', 'contact','emp.var.rate']\n",
    "\n",
    "pivot = trainset.pivot_table(index=\"day_of_week\",values=\"y\")\n",
    "pivot.plot.bar()\n",
    "pivot = trainset.pivot_table(index=\"loan\",values=\"y\")\n",
    "pivot.plot.bar()\n",
    "pyp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process features : func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process a range of values from \n",
    "# @params : df the dataset, column name of column, cut_points the limits, categories names\n",
    "def process_range(df,column,cut_points,categories):\n",
    "    df[column+'_cat'] = pand.cut(df[column],cut_points,labels=categories)\n",
    "    return df\n",
    "\n",
    "# do mapping between values and column\n",
    "# @params df dataframe, column name, mapping (dictionnary)\n",
    "def process_map(df, column, mapping):\n",
    "    df[column+'_cat'] = df[column].map(mapping)\n",
    "    return df\n",
    "\n",
    "# transform column into dummies\n",
    "# @params df dataframe, columnname\n",
    "def process_dummies(df, column):\n",
    "    dummies = pand.get_dummies(df[column],prefix=column)\n",
    "    deleteColumns(dummies.columns, df)\n",
    "    df = pand.concat([df,dummies],axis=1)\n",
    "    return df\n",
    "\n",
    "# process duration by splitting it in interval generated automatically\n",
    "# @params minimum the smallest value of range, maximum the highest, interval of generation\n",
    "def process_duration(minimum,maximum,interval):\n",
    "    ranges = np.arange(minimum, maximum, interval)\n",
    "    arr = []\n",
    "    prev = 0\n",
    "    for c in ranges:\n",
    "        strs =  str(prev) + '-' + str(c) \n",
    "        arr.append(strs)\n",
    "        prev = c\n",
    "\n",
    "    arr.pop()\n",
    "    return ranges,arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>may</td>\n",
       "      <td>487</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age month  duration  pdays  previous     poutcome  cons.conf.idx  y\n",
       "0   30   may       487    999         0  nonexistent          -46.2  0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete features ignored\n",
    "deleteColumns(featureToIgnore, trainset)\n",
    "deleteColumns(featureToIgnore, testset)\n",
    "tmptrain = trainset\n",
    "\n",
    "# features remaining are age, month, duration, pdays, previous, poutcome, cons.conf.idx, y\n",
    "\n",
    "trainset.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ........ After deletion of features ........\n",
    "# Process of feature\n",
    "Here test are made before process to see if column remains.\n",
    "But of course not all of them are used, I kept the code for showing what I tried before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store feature duplicated after dummies\n",
    "featureDup = []\n",
    "\n",
    "# normalize duration and previous\n",
    "norm_duration = True\n",
    "norm_previous = False\n",
    "\n",
    "\n",
    "if norm_duration:\n",
    "    ranges, arr = process_duration(minimum=-5,maximum=4000,interval=30)\n",
    "    trainset = process_range(trainset,'duration',ranges,arr)\n",
    "    testset = process_range(testset,'duration',ranges,arr)\n",
    "    trainset = process_dummies(trainset, 'duration_cat')\n",
    "    testset = process_dummies(testset, 'duration_cat')\n",
    "\n",
    "\n",
    "# add duration_cat column to duplicated features\n",
    "if 'duration_cat' in trainset.columns:\n",
    "    featureDup.append('duration_cat')\n",
    "\n",
    "\n",
    "# the cut above did not function, it was an uniform cut\n",
    "'''\n",
    "# process duration\n",
    "trainset = process_range(trainset,'duration',[-1,364.3,728.6,1092.9,1457.2,1821.5,2185.8,2550.1,2914.4,3278.7,3643.0],\n",
    "                         [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"])\n",
    "testset = process_range(testset,'duration',[-1,364.3,728.6,1092.9,1457.2,1821.5,2185.8,2550.1,2914.4,3278.7,3643.0],\n",
    "                         [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"])\n",
    "trainset = process_dummies(trainset, 'duration_cat')\n",
    "testset = process_dummies(testset, 'duration_cat')\n",
    "'''\n",
    "\n",
    "\n",
    "# process previous\n",
    "if norm_previous:\n",
    "    if 'previous' in trainset.columns:\n",
    "        trainset = process_range(trainset,'previous',[-1,2,5,7],[\"Few\",\"Lot\",\"Much\"])\n",
    "        testset = process_range(testset,'previous',[-1,2,5,7],[\"Few\",\"Lot\",\"Much\"])\n",
    "        trainset = process_dummies(trainset, 'previous_cat')\n",
    "        testset = process_dummies(testset, 'previous_cat')\n",
    "        featureDup.append('previous_cat')\n",
    "        featureDup.append('previous')\n",
    "\n",
    "# explanation : we want here to regroup more likely \"previous\" values into 3 categories, Few, Lot, Much\n",
    "\n",
    "# process age\n",
    "if 'age' in trainset.columns:\n",
    "    trainset = process_range(trainset,'age',[15,29,59,74,100],\n",
    "                             [\"YoungAdult\",\"Adult\",\"Old Adult\",\"Senior\"])\n",
    "    testset = process_range(testset,'age',[15,29,59,74,100],\n",
    "                             [\"YoungAdult\",\"Adult\",\"Old Adult\",\"Senior\"])\n",
    "    trainset = process_dummies(trainset, 'age_cat')\n",
    "    testset = process_dummies(testset, 'age_cat')\n",
    "    featureDup.append('age')\n",
    "    featureDup.append('age_cat')\n",
    "\n",
    "# explanation : create of categories of ages\n",
    "\n",
    "\n",
    "# process job\n",
    "if 'job' in trainset.columns:\n",
    "    mappingJob = {'blue-collar':'job1', 'technician':'job1', 'housemaid':'job1',\n",
    "                  'admin.':'job2', 'management':'job2', 'services':'job2',\n",
    "                  'entrepreneur':'job3', 'self-employed':'job3',\n",
    "                  'retired':'job4', 'unemployed':'job4', 'student':'job4',\n",
    "                  'unknown':'job5'}\n",
    "\n",
    "    trainset = process_map(trainset, 'job', mappingJob)\n",
    "    testset = process_map(testset, 'job', mappingJob)\n",
    "    trainset = process_dummies(trainset, 'job_cat')\n",
    "    testset = process_dummies(testset, 'job_cat')\n",
    "    featureDup.append('job')\n",
    "    featureDup.append('job_cat')\n",
    "\n",
    "\n",
    "# explanation : the idea here was to regroup most common work, like entrepreneur and self-employed into\n",
    "# one group, that was a good idea working better than doing a normal dummies, but job values were not\n",
    "# relevant for unbalanced data unfortunately\n",
    "\n",
    "\n",
    "# process marital\n",
    "if 'marital' in trainset.columns:\n",
    "    trainset = process_dummies(trainset, 'marital')\n",
    "    testset = process_dummies(testset, 'marital')\n",
    "    marital_pivot = trainset.pivot_table(index=\"marital\",values=\"y\")\n",
    "    featureDup.append('marital')\n",
    "\n",
    "# explanation : dummies the marital status\n",
    "\n",
    "# process education\n",
    "if 'education' in trainset.columns:\n",
    "    mappingEdu = {'basic.9y':'edu1', 'basic.6y':'edu1', 'basic.4y':'edu1',\n",
    "                  'high.school':'edu2', 'university.degree':'edu2', 'professional.course':'edu2',\n",
    "                  'unknown':'edu3'}\n",
    "    trainset = process_map(trainset, 'education', mappingEdu)\n",
    "    testset = process_map(testset, 'education', mappingEdu)\n",
    "    trainset = process_dummies(trainset, 'education_cat')\n",
    "    testset = process_dummies(testset, 'education_cat')\n",
    "    featureDup.append('education')\n",
    "    featureDup.append('education_cat')\n",
    "\n",
    "# explanation : as job, I wanted to regroup education into categories, but education was giving bad score\n",
    "\n",
    "\n",
    "\n",
    "# process default\n",
    "if 'default' in trainset.columns:\n",
    "    trainset = process_dummies(trainset, 'default')\n",
    "    trainset['default_yes'] = 0\n",
    "    testset = process_dummies(testset, 'default')\n",
    "    featureDup.append('default')\n",
    "\n",
    "# explanation : as explained before yes value is missing into training, I tried to add a default colum\n",
    "# default_yes to uniform data but not having better results\n",
    "\n",
    "\n",
    "# process housing\n",
    "if 'housing' in trainset.columns:\n",
    "    trainset = process_dummies(trainset, 'housing')\n",
    "    testset = process_dummies(testset, 'housing')\n",
    "    featureDup.append('housing')\n",
    "\n",
    "# explanation : dummies, but not good score\n",
    "\n",
    "\n",
    "\n",
    "# process loan\n",
    "if 'housing' in trainset.columns:\n",
    "    trainset = process_dummies(trainset, 'loan')\n",
    "    testset = process_dummies(testset, 'loan')\n",
    "    featureDup.append('housing')\n",
    "\n",
    "# explanation : dummies, but not good score\n",
    "\n",
    "# process contact => 1 column\n",
    "if 'contact' in trainset.columns:\n",
    "    trainset.loc[trainset['contact'] == 'cellular', 'contact_cat'] = int(1)\n",
    "    trainset.loc[trainset['contact'] == 'telephone', 'contact_cat'] = int(0)\n",
    "    testset.loc[testset['contact'] == 'cellular', 'contact_cat'] = int(1)\n",
    "    testset.loc[testset['contact'] == 'telephone', 'contact_cat'] = int(0)\n",
    "    featureDup.append('contact')\n",
    "    \n",
    "# explanation : dummies, but not good score\n",
    "\n",
    "# process poutcome\n",
    "if 'poutcome' in trainset.columns:\n",
    "    trainset = process_dummies(trainset, 'poutcome')\n",
    "    testset = process_dummies(testset, 'poutcome')\n",
    "    featureDup.append('poutcome')\n",
    "\n",
    "# explanation : dummies\n",
    "\n",
    "# process month\n",
    "if 'month' in trainset.columns:\n",
    "    trainset = process_dummies(trainset, 'month')\n",
    "    testset = process_dummies(testset, 'month')\n",
    "    featureDup.append('month')\n",
    "\n",
    "# explanation : dummies, month is used we can notice in december, march, sept, oct that values of y are high\n",
    "\n",
    "# sorting train and testset by column name\n",
    "trainset = trainset.sort_index(axis=1)\n",
    "testset = testset.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>487</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.313</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital education default housing loan   contact month  \\\n",
       "0   30  blue-collar  married  basic.9y      no     yes   no  cellular   may   \n",
       "\n",
       "  day_of_week  duration  campaign  pdays  previous     poutcome  emp.var.rate  \\\n",
       "0         fri       487         2    999         0  nonexistent          -1.8   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "0          92.893          -46.2      1.313       5099.1  0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old train\n",
    "oldtrain.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>y</th>\n",
       "      <th>duration_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>may</td>\n",
       "      <td>487</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>0</td>\n",
       "      <td>445-475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age month  duration  pdays  previous     poutcome  cons.conf.idx  y  \\\n",
       "0   30   may       487    999         0  nonexistent          -46.2  0   \n",
       "\n",
       "  duration_cat  \n",
       "0      445-475  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train before process\n",
    "tmptrain.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>age_cat_Adult</th>\n",
       "      <th>age_cat_Old Adult</th>\n",
       "      <th>age_cat_Senior</th>\n",
       "      <th>age_cat_YoungAdult</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_cat</th>\n",
       "      <th>duration_cat_-5-25</th>\n",
       "      <th>duration_cat_0--5</th>\n",
       "      <th>duration_cat_1015-1045</th>\n",
       "      <th>duration_cat_1045-1075</th>\n",
       "      <th>duration_cat_1075-1105</th>\n",
       "      <th>duration_cat_1105-1135</th>\n",
       "      <th>duration_cat_1135-1165</th>\n",
       "      <th>duration_cat_115-145</th>\n",
       "      <th>duration_cat_1165-1195</th>\n",
       "      <th>duration_cat_1195-1225</th>\n",
       "      <th>duration_cat_1225-1255</th>\n",
       "      <th>duration_cat_1255-1285</th>\n",
       "      <th>duration_cat_1285-1315</th>\n",
       "      <th>duration_cat_1315-1345</th>\n",
       "      <th>duration_cat_1345-1375</th>\n",
       "      <th>duration_cat_1375-1405</th>\n",
       "      <th>duration_cat_1405-1435</th>\n",
       "      <th>duration_cat_1435-1465</th>\n",
       "      <th>duration_cat_145-175</th>\n",
       "      <th>duration_cat_1465-1495</th>\n",
       "      <th>duration_cat_1495-1525</th>\n",
       "      <th>duration_cat_1525-1555</th>\n",
       "      <th>duration_cat_1555-1585</th>\n",
       "      <th>duration_cat_1585-1615</th>\n",
       "      <th>duration_cat_1615-1645</th>\n",
       "      <th>duration_cat_1645-1675</th>\n",
       "      <th>duration_cat_1675-1705</th>\n",
       "      <th>duration_cat_1705-1735</th>\n",
       "      <th>duration_cat_1735-1765</th>\n",
       "      <th>duration_cat_175-205</th>\n",
       "      <th>duration_cat_1765-1795</th>\n",
       "      <th>duration_cat_1795-1825</th>\n",
       "      <th>duration_cat_1825-1855</th>\n",
       "      <th>duration_cat_1855-1885</th>\n",
       "      <th>duration_cat_1885-1915</th>\n",
       "      <th>duration_cat_1915-1945</th>\n",
       "      <th>duration_cat_1945-1975</th>\n",
       "      <th>duration_cat_1975-2005</th>\n",
       "      <th>duration_cat_2005-2035</th>\n",
       "      <th>duration_cat_2035-2065</th>\n",
       "      <th>duration_cat_205-235</th>\n",
       "      <th>duration_cat_2065-2095</th>\n",
       "      <th>duration_cat_2095-2125</th>\n",
       "      <th>duration_cat_2125-2155</th>\n",
       "      <th>duration_cat_2155-2185</th>\n",
       "      <th>duration_cat_2185-2215</th>\n",
       "      <th>duration_cat_2215-2245</th>\n",
       "      <th>duration_cat_2245-2275</th>\n",
       "      <th>duration_cat_2275-2305</th>\n",
       "      <th>duration_cat_2305-2335</th>\n",
       "      <th>duration_cat_2335-2365</th>\n",
       "      <th>duration_cat_235-265</th>\n",
       "      <th>duration_cat_2365-2395</th>\n",
       "      <th>duration_cat_2395-2425</th>\n",
       "      <th>duration_cat_2425-2455</th>\n",
       "      <th>duration_cat_2455-2485</th>\n",
       "      <th>duration_cat_2485-2515</th>\n",
       "      <th>duration_cat_25-55</th>\n",
       "      <th>duration_cat_2515-2545</th>\n",
       "      <th>duration_cat_2545-2575</th>\n",
       "      <th>duration_cat_2575-2605</th>\n",
       "      <th>duration_cat_2605-2635</th>\n",
       "      <th>duration_cat_2635-2665</th>\n",
       "      <th>duration_cat_265-295</th>\n",
       "      <th>duration_cat_2665-2695</th>\n",
       "      <th>duration_cat_2695-2725</th>\n",
       "      <th>duration_cat_2725-2755</th>\n",
       "      <th>duration_cat_2755-2785</th>\n",
       "      <th>duration_cat_2785-2815</th>\n",
       "      <th>duration_cat_2815-2845</th>\n",
       "      <th>duration_cat_2845-2875</th>\n",
       "      <th>duration_cat_2875-2905</th>\n",
       "      <th>duration_cat_2905-2935</th>\n",
       "      <th>duration_cat_2935-2965</th>\n",
       "      <th>duration_cat_295-325</th>\n",
       "      <th>duration_cat_2965-2995</th>\n",
       "      <th>duration_cat_2995-3025</th>\n",
       "      <th>duration_cat_3025-3055</th>\n",
       "      <th>duration_cat_3055-3085</th>\n",
       "      <th>duration_cat_3085-3115</th>\n",
       "      <th>duration_cat_3115-3145</th>\n",
       "      <th>duration_cat_3145-3175</th>\n",
       "      <th>duration_cat_3175-3205</th>\n",
       "      <th>duration_cat_3205-3235</th>\n",
       "      <th>duration_cat_3235-3265</th>\n",
       "      <th>duration_cat_325-355</th>\n",
       "      <th>duration_cat_3265-3295</th>\n",
       "      <th>duration_cat_3295-3325</th>\n",
       "      <th>duration_cat_3325-3355</th>\n",
       "      <th>duration_cat_3355-3385</th>\n",
       "      <th>duration_cat_3385-3415</th>\n",
       "      <th>duration_cat_3415-3445</th>\n",
       "      <th>duration_cat_3445-3475</th>\n",
       "      <th>duration_cat_3475-3505</th>\n",
       "      <th>duration_cat_3505-3535</th>\n",
       "      <th>duration_cat_3535-3565</th>\n",
       "      <th>duration_cat_355-385</th>\n",
       "      <th>duration_cat_3565-3595</th>\n",
       "      <th>duration_cat_3595-3625</th>\n",
       "      <th>duration_cat_3625-3655</th>\n",
       "      <th>duration_cat_3655-3685</th>\n",
       "      <th>duration_cat_3685-3715</th>\n",
       "      <th>duration_cat_3715-3745</th>\n",
       "      <th>duration_cat_3745-3775</th>\n",
       "      <th>duration_cat_3775-3805</th>\n",
       "      <th>duration_cat_3805-3835</th>\n",
       "      <th>duration_cat_3835-3865</th>\n",
       "      <th>duration_cat_385-415</th>\n",
       "      <th>duration_cat_3865-3895</th>\n",
       "      <th>duration_cat_3895-3925</th>\n",
       "      <th>duration_cat_3925-3955</th>\n",
       "      <th>duration_cat_415-445</th>\n",
       "      <th>duration_cat_445-475</th>\n",
       "      <th>duration_cat_475-505</th>\n",
       "      <th>duration_cat_505-535</th>\n",
       "      <th>duration_cat_535-565</th>\n",
       "      <th>duration_cat_55-85</th>\n",
       "      <th>duration_cat_565-595</th>\n",
       "      <th>duration_cat_595-625</th>\n",
       "      <th>duration_cat_625-655</th>\n",
       "      <th>duration_cat_655-685</th>\n",
       "      <th>duration_cat_685-715</th>\n",
       "      <th>duration_cat_715-745</th>\n",
       "      <th>duration_cat_745-775</th>\n",
       "      <th>duration_cat_775-805</th>\n",
       "      <th>duration_cat_805-835</th>\n",
       "      <th>duration_cat_835-865</th>\n",
       "      <th>duration_cat_85-115</th>\n",
       "      <th>duration_cat_865-895</th>\n",
       "      <th>duration_cat_895-925</th>\n",
       "      <th>duration_cat_925-955</th>\n",
       "      <th>duration_cat_955-985</th>\n",
       "      <th>duration_cat_985-1015</th>\n",
       "      <th>month</th>\n",
       "      <th>month_apr</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>487</td>\n",
       "      <td>445-475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>may</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age age_cat  age_cat_Adult  age_cat_Old Adult  age_cat_Senior  \\\n",
       "0   30   Adult              1                  0               0   \n",
       "\n",
       "   age_cat_YoungAdult  cons.conf.idx  duration duration_cat  \\\n",
       "0                   0          -46.2       487      445-475   \n",
       "\n",
       "   duration_cat_-5-25  duration_cat_0--5  duration_cat_1015-1045  \\\n",
       "0                   0                  0                       0   \n",
       "\n",
       "   duration_cat_1045-1075  duration_cat_1075-1105  duration_cat_1105-1135  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1135-1165  duration_cat_115-145  duration_cat_1165-1195  \\\n",
       "0                       0                     0                       0   \n",
       "\n",
       "   duration_cat_1195-1225  duration_cat_1225-1255  duration_cat_1255-1285  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1285-1315  duration_cat_1315-1345  duration_cat_1345-1375  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1375-1405  duration_cat_1405-1435  duration_cat_1435-1465  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_145-175  duration_cat_1465-1495  duration_cat_1495-1525  \\\n",
       "0                     0                       0                       0   \n",
       "\n",
       "   duration_cat_1525-1555  duration_cat_1555-1585  duration_cat_1585-1615  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1615-1645  duration_cat_1645-1675  duration_cat_1675-1705  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1705-1735  duration_cat_1735-1765  duration_cat_175-205  \\\n",
       "0                       0                       0                     0   \n",
       "\n",
       "   duration_cat_1765-1795  duration_cat_1795-1825  duration_cat_1825-1855  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1855-1885  duration_cat_1885-1915  duration_cat_1915-1945  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1945-1975  duration_cat_1975-2005  duration_cat_2005-2035  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_2035-2065  duration_cat_205-235  duration_cat_2065-2095  \\\n",
       "0                       0                     0                       0   \n",
       "\n",
       "   duration_cat_2095-2125  duration_cat_2125-2155  duration_cat_2155-2185  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_2185-2215  duration_cat_2215-2245  duration_cat_2245-2275  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_2275-2305  duration_cat_2305-2335  duration_cat_2335-2365  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_235-265  duration_cat_2365-2395  duration_cat_2395-2425  \\\n",
       "0                     0                       0                       0   \n",
       "\n",
       "   duration_cat_2425-2455  duration_cat_2455-2485  duration_cat_2485-2515  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_25-55  duration_cat_2515-2545  duration_cat_2545-2575  \\\n",
       "0                   0                       0                       0   \n",
       "\n",
       "   duration_cat_2575-2605  duration_cat_2605-2635  duration_cat_2635-2665  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_265-295  duration_cat_2665-2695  duration_cat_2695-2725  \\\n",
       "0                     0                       0                       0   \n",
       "\n",
       "   duration_cat_2725-2755  duration_cat_2755-2785  duration_cat_2785-2815  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_2815-2845  duration_cat_2845-2875  duration_cat_2875-2905  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_2905-2935  duration_cat_2935-2965  duration_cat_295-325  \\\n",
       "0                       0                       0                     0   \n",
       "\n",
       "   duration_cat_2965-2995  duration_cat_2995-3025  duration_cat_3025-3055  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3055-3085  duration_cat_3085-3115  duration_cat_3115-3145  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3145-3175  duration_cat_3175-3205  duration_cat_3205-3235  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3235-3265  duration_cat_325-355  duration_cat_3265-3295  \\\n",
       "0                       0                     0                       0   \n",
       "\n",
       "   duration_cat_3295-3325  duration_cat_3325-3355  duration_cat_3355-3385  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3385-3415  duration_cat_3415-3445  duration_cat_3445-3475  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3475-3505  duration_cat_3505-3535  duration_cat_3535-3565  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_355-385  duration_cat_3565-3595  duration_cat_3595-3625  \\\n",
       "0                     0                       0                       0   \n",
       "\n",
       "   duration_cat_3625-3655  duration_cat_3655-3685  duration_cat_3685-3715  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3715-3745  duration_cat_3745-3775  duration_cat_3775-3805  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3805-3835  duration_cat_3835-3865  duration_cat_385-415  \\\n",
       "0                       0                       0                     0   \n",
       "\n",
       "   duration_cat_3865-3895  duration_cat_3895-3925  duration_cat_3925-3955  \\\n",
       "0                       0                       0                       0   \n",
       "\n",
       "   duration_cat_415-445  duration_cat_445-475  duration_cat_475-505  \\\n",
       "0                     0                     1                     0   \n",
       "\n",
       "   duration_cat_505-535  duration_cat_535-565  duration_cat_55-85  \\\n",
       "0                     0                     0                   0   \n",
       "\n",
       "   duration_cat_565-595  duration_cat_595-625  duration_cat_625-655  \\\n",
       "0                     0                     0                     0   \n",
       "\n",
       "   duration_cat_655-685  duration_cat_685-715  duration_cat_715-745  \\\n",
       "0                     0                     0                     0   \n",
       "\n",
       "   duration_cat_745-775  duration_cat_775-805  duration_cat_805-835  \\\n",
       "0                     0                     0                     0   \n",
       "\n",
       "   duration_cat_835-865  duration_cat_85-115  duration_cat_865-895  \\\n",
       "0                     0                    0                     0   \n",
       "\n",
       "   duration_cat_895-925  duration_cat_925-955  duration_cat_955-985  \\\n",
       "0                     0                     0                     0   \n",
       "\n",
       "   duration_cat_985-1015 month  month_apr  month_aug  month_dec  month_jul  \\\n",
       "0                      0   may          0          0          0          0   \n",
       "\n",
       "   month_jun  month_mar  month_may  month_nov  month_oct  month_sep  pdays  \\\n",
       "0          0          0          1          0          0          0    999   \n",
       "\n",
       "      poutcome  poutcome_failure  poutcome_nonexistent  poutcome_success  \\\n",
       "0  nonexistent                 0                     1                 0   \n",
       "\n",
       "   previous  y  \n",
       "0         0  0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train after pre-process\n",
    "trainset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAAKACAYAAADtk6MaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xvw3Xdd5/HXm6QlKCBQomBTSJCyUBSkDVUuckeKIKWA\nUhRRC1O7WhnWcbSzrCjrrAvLyqBQ7BQXEHXtLnLZshTKLlZArkm5FFsuZkq1QcFQGG5S2tL3/vE7\nxUP21+TX5Pxyzu98Ho+ZTM/38/32/N6dyZyePPO9VHcHAAAAgHHcat4DAAAAAHBkCUIAAAAAgxGE\nAAAAAAYjCAEAAAAMRhACAAAAGIwgBAAAADAYQQgAAABgMIIQAAAAwGAEIQAAAIDBbJ7XD77zne/c\n27dvn9ePBwAAAFg6l1566Re6e+vBjptbENq+fXt27949rx8PAAAAsHSq6u/XcpxLxgAAAAAGIwgB\nAAAADEYQAgAAABjM3O4hBAAAALCIrr/++uzduzfXXnvtvEe5WVu2bMm2bdty1FFHHdK/LwgBAAAA\nTNm7d29ud7vbZfv27amqeY/z/+nuXHPNNdm7d2927NhxSO/hkjEAAACAKddee22OOeaYhYxBSVJV\nOeaYYw7rDCZBCAAAAGA/ixqDbnK48wlCAAAAAINxDyEAAACAA9h+zltn+n5XvegJM32/Q+EMIQAA\nAIDBCEIAAAAAC+YFL3hBXvayl317+/nPf37+4A/+YGbvLwgBAAAALJgzzjgjr3vd65IkN954Yy64\n4II885nPnNn7u4cQAAAAwILZvn17jjnmmHzkIx/J5z//+TzgAQ/IMcccM7P3F4QAAAAAFtBznvOc\nvPa1r83nPve5nHHGGTN9b5eMAQAAACyg0047LW9/+9uza9euPO5xj5vpeztDCAAAAOAA5vWY+KOP\nPjqPfOQjc4c73CGbNm2a6XsLQgAAAAAL6MYbb8wHPvCBvP71r5/5e7tkDAAAAGDBXHHFFbnnPe+Z\nRz/60Tn++ONn/v7OEAIAAABYMCeccEKuvPLKdXt/ZwgBAAAA7Ke75z3CAR3ufIIQAAAAwJQtW7bk\nmmuuWdgo1N255pprsmXLlkN+D5eMAQAAAEzZtm1b9u7dm3379s17lJu1ZcuWbNu27ZD/fUEIAAAA\nYMpRRx2VHTt2zHuMdeWSMQAAAIDBOEMIAACAhbH9nLfOewQ2iKte9IR5j7ChOUMIAAAAYDCCEAAA\nAMBgBCEAAACAwQhCAAAAAIMRhAAAAAAGs6YgVFWnVNWnqmpPVZ1zM8c8oqo+WlWXV9W7ZjsmAAAA\nALNy0MfOV9WmJOcmeWySvUl2VdWF3X3F1DF3SPLKJKd09z9U1feu18AAAAAAHJ61nCF0cpI93X1l\nd1+X5IIkp+53zM8keWN3/0OSdPc/z3ZMAAAAAGZlLUHo2CRXT23vnaxNu1eSO1bVX1fVpVX1rFkN\nCAAAAMBsHfSSsVvwPicleXSS2yR5f1V9oLs/PX1QVZ2Z5Mwkudvd7jajHw0AAADALbGWM4Q+m+S4\nqe1tk7Vpe5Nc3N1f7+4vJHl3kvvv/0bdfX537+zunVu3bj3UmQEAAAA4DGsJQruSHF9VO6rq6CSn\nJ7lwv2P+V5KHVtXmqvquJD+S5BOzHRUAAACAWTjoJWPdfUNVnZ3k4iSbkry6uy+vqrMm+8/r7k9U\n1duTXJbkxiR/3N1/u56DAwAAAHBo1nQPoe6+KMlF+62dt9/2S5K8ZHajAQAAALAe1nLJGAAAAABL\nRBACAAAAGIwgBAAAADAYQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAM\nRhACAAAAGIwgBAAAADAYQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAM\nRhACAAAAGIwgBAAAADAYQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAM\nRhACAAAAGIwgBAAAADAYQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAM\nRhACAAAAGIwgBAAAADAYQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAM\nRhACAAAAGIwgBAAAADAYQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAM\nRhACAAAAGIwgBAAAADAYQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAM\nRhACAAAAGIwgBAAAADAYQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAM\nRhACAAAAGIwgBAAAADAYQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAM\nRhACAAAAGIwgBAAAADAYQQgAAABgMGsKQlV1SlV9qqr2VNU5q+x/RFV9uao+Ovn1gtmPCgAAAMAs\nbD7YAVW1Kcm5SR6bZG+SXVV1YXdfsd+h7+nuJ67DjAAAAADM0FrOEDo5yZ7uvrK7r0tyQZJT13cs\nAAAAANbLWoLQsUmuntreO1nb34Or6rKqeltV3Xe1N6qqM6tqd1Xt3rdv3yGMCwAAAMDhmtVNpT+c\n5G7dfb8kL0/y5tUO6u7zu3tnd+/cunXrjH40AAAAALfEWoLQZ5McN7W9bbL2bd39le7+2uT1RUmO\nqqo7z2xKAAAAAGZmLUFoV5Ljq2pHVR2d5PQkF04fUFV3qaqavD558r7XzHpYAAAAAA7fQZ8y1t03\nVNXZSS5OsinJq7v78qo6a7L/vCRPS/Jvq+qGJN9Icnp39zrODQAAAMAhOmgQSr59GdhF+62dN/X6\nFUleMdvRAAAAAFgPs7qpNAAAAAAbhCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEIQgAAAACD\nEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEIQgAAAACD\nEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEIQgAAAACD\nEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEIQgAAAACD\nEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEIQgAAAACD\nEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEIQgAAAACD\nEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEIQgAAAACD\nEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEIQgAAAACD\nEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEIQgAAAACD\nEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwawpCVXVKVX2qqvZU1TkHOO6BVXVD\nVT1tdiMCAAAAMEsHDUJVtSnJuUken+SEJM+oqhNu5rgXJ3nHrIcEAAAAYHbWcobQyUn2dPeV3X1d\nkguSnLrKcb+a5A1J/nmG8wEAAAAwY2sJQscmuXpqe+9k7duq6tgkpyX5o9mNBgAAAMB6mNVNpV+W\n5De7+8YDHVRVZ1bV7qravW/fvhn9aAAAAABuic1rOOazSY6b2t42WZu2M8kFVZUkd07yE1V1Q3e/\nefqg7j4/yflJsnPnzj7UoQEAAAA4dGsJQruSHF9VO7ISgk5P8jPTB3T3jpteV9Vrk/zv/WMQAAAA\nAIvhoEGou2+oqrOTXJxkU5JXd/flVXXWZP956zwjAAAAADO0ljOE0t0XJblov7VVQ1B3/8LhjwUA\nAADAepnVTaUBAAAA2CAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAMRhACAAAAGIwgBAAAADAY\nQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAMRhACAAAAGIwgBAAAADAY\nQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAMRhACAAAAGIwgBAAAADAY\nQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAMRhACAAAAGIwgBAAAADAY\nQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAMRhACAAAAGIwgBAAAADAY\nQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAMRhACAAAAGIwgBAAAADAY\nQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAMRhACAAAAGIwgBAAAADAY\nQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAMRhACAAAAGIwgBAAAADAY\nQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAYjCAEAAAAMRhACAAAAGIwgBAAAADAY\nQQgAAABgMIIQAAAAwGAEIQAAAIDBCEIAAAAAgxGEAAAAAAazpiBUVadU1aeqak9VnbPK/lOr6rKq\n+mhV7a6qh85+VAAAAABmYfPBDqiqTUnOTfLYJHuT7KqqC7v7iqnD3pnkwu7uqrpfkv+Z5N7rMTAA\nAAAAh2ctZwidnGRPd1/Z3dcluSDJqdMHdPfXursnm9+dpAMAAADAQlpLEDo2ydVT23sna9+hqk6r\nqk8meWuSM2YzHgAAAACzNrObSnf3m7r73kmenOR3Vzumqs6c3GNo9759+2b1owEAAAC4BdYShD6b\n5Lip7W2TtVV197uT3KOq7rzKvvO7e2d379y6destHhYAAACAw7eWILQryfFVtaOqjk5yepILpw+o\nqntWVU1en5jk1kmumfWwAAAAABy+gz5lrLtvqKqzk1ycZFOSV3f35VV11mT/eUmemuRZVXV9km8k\nefrUTaYBAAAAWCAHDUJJ0t0XJblov7Xzpl6/OMmLZzsaAAAAAOthZjeVBgAAAGBjEIQAAAAABiMI\nAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEIQgAAAACDEYQAAAAABiMI\nAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEIQgAAAACDEYQAAAAABiMI\nAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEIQgAAAACDEYQAAAAABiMI\nAQAAAAxGEAIAAAAYjCAEAAAAMJjN8x4AAICNafs5b533CGwQV73oCfMeAYD9OEMIAAAAYDCCEAAA\nAMBgBCEAAACAwQhCAAAAAIMRhAAAAAAGIwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCCEAAA\nAMBgBCEAAACAwQhCAAAAAIMRhAAAAAAGIwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCCEAAA\nAMBgBCEAAACAwQhCAAAAAIMRhAAAAAAGIwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCCEAAA\nAMBgBCEAAACAwQhCAAAAAIMRhAAAAAAGIwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCCEAAA\nAMBgBCEAAACAwQhCAAAAAIMRhAAAAAAGIwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCCEAAA\nAMBgBCEAAACAwQhCAAAAAIMRhAAAAAAGIwgBAAAADGZNQaiqTqmqT1XVnqo6Z5X9P1tVl1XVx6vq\nfVV1/9mPCgAAAMAsHDQIVdWmJOcmeXySE5I8o6pO2O+wzyR5eHf/UJLfTXL+rAcFAAAAYDbWcobQ\nyUn2dPeV3X1dkguSnDp9QHe/r7u/NNn8QJJtsx0TAAAAgFlZSxA6NsnVU9t7J2s359lJ3rbajqo6\ns6p2V9Xuffv2rX1KAAAAAGZmpjeVrqpHZiUI/eZq+7v7/O7e2d07t27dOssfDQAAAMAabV7DMZ9N\nctzU9rbJ2neoqvsl+eMkj+/ua2YzHgAAAACztpYzhHYlOb6qdlTV0UlOT3Lh9AFVdbckb0zyc939\n6dmPCQAAAMCsHPQMoe6+oarOTnJxkk1JXt3dl1fVWZP95yV5QZJjkryyqpLkhu7euX5jAwAAAHCo\n1nLJWLr7oiQX7bd23tTr5yR5zmxHAwAAAGA9zPSm0gAAAAAsPkEIAAAAYDCCEAAAAMBgBCEAAACA\nwQhCAAAAAIMRhAAAAAAGIwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCCEAAAAMBgBCEAAACA\nwQhCAAAAAIMRhAAAAAAGIwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCCEAAAAMBgBCEAAACA\nwQhCAAAAAIMRhAAAAAAGIwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCCEAAAAMBgBCEAAACA\nwQhCAAAAAIMRhAAAAAAGIwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCCEAAAAMBgBCEAAACA\nwQhCAAAAAIMRhAAAAAAGIwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCCEAAAAMBgBCEAAACA\nwQhCAAAAAIMRhAAAAAAGIwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCCEAAAAMBgBCEAAACA\nwQhCAAAAAIMRhAAAAAAGIwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCCEAAAAMBgBCEAAACA\nwQhCAAAAAIMRhAAAAAAGIwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCCEAAAAMBgBCEAAACA\nwWye9wB8p+3nvHXeI7BBXPWiJ8x7BAAAADYoZwgBAAAADEYQAgAAABiMIAQAAAAwGEEIAAAAYDCC\nEAAAAMBgBCEAAACAwQhCAAAAAINZUxCqqlOq6lNVtaeqzlll/72r6v1V9c2q+vXZjwkAAADArGw+\n2AFVtSnJuUkem2Rvkl1VdWF3XzF12BeTPDfJk9dlSgAOy/Zz3jrvEdggrnrRE+Y9AgAAR8BazhA6\nOcme7r6yu69LckGSU6cP6O5/7u5dSa5fhxkBAAAAmKG1BKFjk1w9tb13snaLVdWZVbW7qnbv27fv\nUN4CAAAAgMN0RG8q3d3nd/fO7t65devWI/mjAQAAAJhYSxD6bJLjpra3TdYAAAAA2IDWEoR2JTm+\nqnZU1dFJTk9y4fqOBQAAAMB6OehTxrr7hqo6O8nFSTYleXV3X15VZ032n1dVd0myO8ntk9xYVc9L\nckJ3f2UdZwcAAADgEBw0CCVJd1+U5KL91s6bev25rFxKBgAAAMCCO6I3lQYAAABg/gQhAAAAgMEI\nQgAAAACDEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEI\nQgAAAACDEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEI\nQgAAAACDEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEI\nQgAAAACDEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEI\nQgAAAACDEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEI\nQgAAAACDEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEI\nQgAAAACDEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEI\nQgAAAACDEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEI\nQgAAAACDEYQAAAAABiMIAQAAAAxGEAIAAAAYjCAEAAAAMBhBCAAAAGAwghAAAADAYAQhAAAAgMEI\nQgAAAACDWVMQqqpTqupTVbWnqs5ZZX9V1R9O9l9WVSfOflQAAAAAZuGgQaiqNiU5N8njk5yQ5BlV\ndcJ+hz0+yfGTX2cm+aMZzwkAAADAjKzlDKGTk+zp7iu7+7okFyQ5db9jTk3yul7xgSR3qKq7znhW\nAAAAAGZgLUHo2CRXT23vnazd0mMAAAAAWACbj+QPq6ozs3JJWZJ8rao+dSR/PhvanZN8Yd5DLJJ6\n8bwngKXgs2U/PltgJny27MdnC8yEz5b9+Gy5WXdfy0FrCUKfTXLc1Pa2ydotPSbdfX6S89cyGEyr\nqt3dvXPecwDLxWcLsB58tgDrwWcLs7aWS8Z2JTm+qnZU1dFJTk9y4X7HXJjkWZOnjf1oki939z/N\neFYAAAAAZuCgZwh19w1VdXaSi5NsSvLq7r68qs6a7D8vyUVJfiLJniT/kuQX129kAAAAAA7Hmu4h\n1N0XZSX6TK+dN/W6k/zKbEeD7+BSQ2A9+GwB1oPPFmA9+Gxhpmql5QAAAAAwirXcQwgAAACAJSII\nAQAAAAxGEGIhTZ5Wd9A1AIB5q6qHrGUNABaJIMSieuUqa+ce8SmApVJVO9ayBnALvXyNawBrUlWb\nqurP5z0Hy21NTxmDI6WqTk7yoCRbq+q5U7tun+So+UwFLJE3JDlxv7W/THLSHGYBNriqelCSB2fl\ne8uvTe26fZJN85kKWAbd/a2quntVHd3d1817HpaTIMSi+e4kd87K782tU+tfTfJTc5kI2PCq6t5J\n7pvke6rqKVO7bp9ky3ymApbA0Ulum5XvLbebWv9KkqfNZSJgmVyZ5L1VdWGSr9+02N0vnd9ILBOP\nnWchVdU9uvvKec8BLIeqOjXJk5M8KcmFU7u+muSC7n7fXAYDlkJV3b27/37ecwDLpap+e7X17n7h\nkZ6F5SQIsVCq6k1JbvY3ZXc/5eb2ARxMVT2ou98/7zmA5VBVb8mBv7c86QiOAyypqrptknT31+Y9\nC8tFEGKhVNWjD7S/u995pGYBlkdVvTwH/kPbc29uH8DNqaqHH2h/d7/rSM0CLJ+q+sEkf5rkTpOl\nLyR5VndfPr+pWCbuIcRCEXyAdbJ73gMAy0fwAdbZ+Ul+rbsvSZKqekSSV2XlZvZw2JwhxEKqqr/L\nKn+b3933msM4AAA3q6o+k9W/t9xjDuMAS6KqPtbd9z/YGhwqZwixqB469XpLVp4w9j1zmgVYElV1\nSVb/Q9uj5jAOsDx2Tr2+6XvLnW7mWIC1urKqfisrl40lyTOz8uQxmAlnCLFhVNXu7t558CMBVldV\nJ01tbkny1CQ3dPdvzGkkYElV1aXdfdLBjwRYXVXdMckL869/Wf6eJL/T3V+a31QsE2cIsZCq6n5T\nm7fKyt+83XpO4wBLorsv3W/pvVX1obkMAyyNqjpxavOm7y2+ZwOHZRJ+PPiCdeN/VCyqc6de35Dk\nqiRPn88owLKoqulLOG6V5KS4HBU4fL8/9fqm7y0/PZ9RgI2uql7W3c+rqrdk9UvdnzSHsVhCLhkD\nYBhTN36trPyh7TNJ/mN3/81cBwMAmKiqk7r70qp6+Gr7PeGQWRGEWChVdcBTIrv7D4/ULAAAB1JV\nv3ag/d390iM1CwDcUi4ZY9Fsnfzz+CQnJ3nLZPuJST6YRBACbrGqesqB9nf3G4/ULMBSud3kn/8m\nyQOTXDjZ/skk7k8GHJaqekiS30ly96z82b2SdHffY55zsTycIcRCqqp3J3lid39lsn37JG/p7lVP\nmwQ4kKp6zeTl9yZ5cJK/mmw/Msn7uvuJcxkMWAqT7y1P6O6vTrZvl+St3f2w+U4GbGRV9ckk/y7J\npUm+ddN6d18zt6FYKs4QYlF9X5Jrp7a/meQuc5oF2OC6+xeTpKrekeSE7v6nyfZdk7x2jqMBy+H7\nklw3tX3dZA3gcHy5u9827yFYXoIQi+rPk3ywqt4w2T4tyZ/NcR5gORx3Uwya+HxWTsMGOByvS/Kh\nqnrTZPvJSf5kjvMAy+GSqnpJkjdm5S/IkyTd/eH5jcQycckYC6uqHpjkplOt393du+Y5D7DxVdUr\nsnKPsr+YLD09yd919wFvaA9wMFV1YpIfm2y+u7s/Ms95gI2vqi5ZZbm7+1FHfBiWkiDEwquq22Tl\nb9pO7+5T5z0PsLFV1Wn519j8xSR36e5fmeNIwBKpqu9O8pSsfG95wrznAYCbc6t5DwCrqarNVfWT\nVfUXSf4pyU/EfT6A2bgqyQ1ZuRT1UUk+MddpgA2vqo6uqtOq6vVZ+d7yqCTnzXksYIOrqu+rqv9W\nVW+bbJ9QVc+e91wsD2cIsVCq6lFJnpGVAPSeJP8jycu62z0+gENWVffKymfLM5J8ISufLb/uswU4\nHFX141n5XPnxJJdk5bPl5d29fZ5zActhEoJek+T53X3/qtqc5CPd/UNzHo0lIQixUKrqxqyEoJ/v\n7qsma1d29z3mOhiwoU19tjy7u/dM1ny2AIdl6rPlF7r7M5M1ny3ATFTVru5+YFV9pLsfMFn7aHf/\n8LxnYzm4ZIxFc3KSXVm5o/7bqurnk2ya80zAxveUrFzGcUlVvaqqHp2k5jwTsPGdmOT9Sf5vVf2f\nyaUcvrcAs/L1qjomSSdJVf1oki/PdySWiTOEWEhVVVl5UsczsvIHuQ8leVN3v3qugwEb2uRmr6dm\n5bPlUVl5VPSbuvsdcx0M2PCq6sFZ+Wx5apKPZeWz5fz5TgVsZJOnF748yQ8m+dskW5M8rbsvm+tg\nLA1BiIVIOs5sAAAHSklEQVQ3uVb2x7PytI5nzXseYDlU1R2T/FSSp3f3o+c9D7AcqupWSR6Tle8t\nZ8x7HmDjqaoHJrm6uz83+bPQL2UlNl+R5AXd/cW5DsjSEIRYSFV1v1WWv5yVD8Ybj/Q8AAAAR0JV\nfTjJY7r7i1X1sCQXJPnVJD+c5D7d/bS5DsjSEIRYSFW1KysfeJdn5T4f98lKEb9dkjO7+51zHA8A\nAGBdVNXHuvv+k9fnJtnX3b8z2XZTaWbGTaVZVFclOam7f3jyYXhSkk8neVyS35/nYAAAAOto0+RS\nsSR5dJK/mtq3eZXj4ZD4zcSius/0zdK6++NVdUJ371m53zQAwHxV1Z0OtN99PoBD9BdJ3lVVX0jy\njSTvSZKqumc8ZYwZcskYC6mq/jIrj4i+YLL09CTfn+Rnk7y3u3fOazYAgCSpqs9k5XHQleRuSb40\neX2HJP/Q3TvmOB6wgU0eMX/XJO/o7q9P1u6V5Lbd/eG5DsfSEIRYSFX1XVm5cdpDJ0vvzcojF6/N\nyoegMg4ALISqelVWHjN/0WT78Ume3N2/NN/JAODmCUIAAHAYqurj3f1DB1sDgEXiHkIspMkpkr+d\n5O6Z+n3a3fea21AAAKv7x6r6D0n+bLL9s0n+cY7zAMBBOUOIhVRVn0jyG0kuTfKtm9a7+/NzGwoA\nYBWTm0v/dpKHTZbeneSFbioNwCIThFhIVfXB7v6Rec8BAAAAy0gQYiFV1X+evHxjkm/etD79KHoA\ngHmqqrdk5Sljq+ruJx3BcQDgFhGEWEhV9Z5Vlru7H7bKOgDAEVdVDz/Q/u5+15GaBQBuKUEIAAAO\nQ1VtSXLPyeae7r52nvMAwFoIQiykqvr3q6139+8d6VkAAFZTVZuT/F6SM5L8fZJKclyS1yR5fndf\nP8fxAOCAbjXvAeBmfGvq11FJnpzk+LlOBADwnV6S5E5JdnT3Sd19YpIfSHKHJP91rpMBwEE4Q4gN\nYXIq9tu7+xHzngUAIEmq6u+S3Kv3+0JdVZuSfLK7/WUWAAvLGUJsFLdOsm3eQwAATOn9Y9Bk8Vs5\nwNPHAGARbJ73ALCaqvpI/vWL1KYkd83KNfoAAIviiqp6Vne/bnqxqp6Z5JNzmgkA1sQlYyykqvqB\nqc0bknyuu785r3kAAPZXVccmeWOSbyS5dLK8M8ltkpzW3Z+d12wAcDCCEAurqu6b5Mcmm+/u7ivm\nOQ8AwGqq6lFJ7jvZvKK73znPeQBgLQQhFlJVnZ3kl5O8ebJ0apJzu/uV85sKAAAAloMgxEKqqsuS\nPLi7vzbZvm2S93X3/eY7GQAAAGx8njLGoqok101tXz9ZAwAAAA6Tp4yxqP40yQer6g2T7dOS/Mkc\n5wEAAICl4ZIxFkpVXZTkl7v7qqr6kSQPmex6T3fvmuNoAAAAsDQEIRZKVf1Ukv+UlbOB/kt3Xz/n\nkQAAAGDpCEIsnMkNpH8rySlZuXTsxpv2dfdL5zUXAAAALAv3EGIRXZfk60luneR2mQpCAAAAwOET\nhFgoVXVKkpcmuTDJid39L3MeCQAAAJaOS8ZYKFX1niRndffl854FAAAAlpUgBAAAADCYW817AAAA\nAACOLEEIAAAAYDCCEADAOquq51XVd817DgCAm7iHEADAOquqq5Ls7O4vzHsWAIDEGUIAwBKrqjdX\n1aVVdXlVnTlZe3ZVfbqqPlRVr6qqV0zWt1bVG6pq1+TXQw7wvretqtdU1cer6rKqeupk/Y+qavfk\n571wsvbcJN+f5JKqumT9/6sBAA7OGUIAwNKqqjt19xer6jZJdiV5XJL3JjkxyVeT/FWSj3X32VX1\n35O8srv/pqruluTi7r7Pzbzvi5PcurufN9m+Y3d/aernbUryziTP7e7LnCEEACyazfMeAABgHT23\nqk6bvD4uyc8leVd3fzFJqur1Se412f+YJCdU1U3/7u2r6rbd/bVV3vcxSU6/aaO7vzR5+dOTM5E2\nJ7lrkhOSXDbD/x4AgJkQhACApVRVj8hKuHlQd/9LVf11kk8mWfWsn6xcSv+j3X3tIf68HUl+PckD\nJ2cLvTbJlkN5LwD4f+3csY4PYRTG4d9JdIJs5RaUCoVOlGpXoJNscAsKEdegUGophVoiGjbZUNKo\nZSPqUex/k42gwS47z9PN5OTLN+2bMy/8bTqEAICT6lz1eRMGXaguV6erKzOzNTOnquuH5p9Xtw4e\nZubiL85+UW0fmt2qzlZfq72ZOV9dOzT/pTrzm98DAPDHCIQAgJPqWXVqZt5XD6pX1afqfvW6/S6h\nj9XeZv52dWlTEv2uuvmLs+9VWzOzOzM71dVlWXaqN+1vIT3enH/gYfVMqTQA8K9QKg0ArMpBL9Bm\nQ+hJ9WhZlifHfS8AgKNkQwgAWJu7M/O22q0+VE+P+T4AAEfOhhAAwE/MzI3qznevXy7Lsv2jeQCA\n/4VACAAAAGBl/DIGAAAAsDICIQAAAICVEQgBAAAArIxACAAAAGBlBEIAAAAAKyMQAgAAAFiZb61I\nLeiB9gcXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115ad6f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# again the goal here is to re-do plot to see if normalization worked well or not\n",
    "\n",
    "pivot = trainset.pivot_table(index=\"age_cat\",values=\"y\")\n",
    "pivot.plot.bar(figsize=(20,10))\n",
    "pyp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate features : keep dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting this duplication =  ['duration_cat', 'age', 'age_cat', 'poutcome', 'month']\n"
     ]
    }
   ],
   "source": [
    "# we remove useless column, that we have dummies or cut\n",
    "print(\"Deleting this duplication = \", featureDup)\n",
    "deleteColumns(featureDup, trainset)\n",
    "deleteColumns(featureDup, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_cat_Adult</th>\n",
       "      <th>age_cat_Old Adult</th>\n",
       "      <th>age_cat_Senior</th>\n",
       "      <th>age_cat_YoungAdult</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_cat_-5-25</th>\n",
       "      <th>duration_cat_0--5</th>\n",
       "      <th>duration_cat_1015-1045</th>\n",
       "      <th>duration_cat_1045-1075</th>\n",
       "      <th>duration_cat_1075-1105</th>\n",
       "      <th>duration_cat_1105-1135</th>\n",
       "      <th>duration_cat_1135-1165</th>\n",
       "      <th>duration_cat_115-145</th>\n",
       "      <th>duration_cat_1165-1195</th>\n",
       "      <th>duration_cat_1195-1225</th>\n",
       "      <th>duration_cat_1225-1255</th>\n",
       "      <th>duration_cat_1255-1285</th>\n",
       "      <th>duration_cat_1285-1315</th>\n",
       "      <th>duration_cat_1315-1345</th>\n",
       "      <th>duration_cat_1345-1375</th>\n",
       "      <th>duration_cat_1375-1405</th>\n",
       "      <th>duration_cat_1405-1435</th>\n",
       "      <th>duration_cat_1435-1465</th>\n",
       "      <th>duration_cat_145-175</th>\n",
       "      <th>duration_cat_1465-1495</th>\n",
       "      <th>duration_cat_1495-1525</th>\n",
       "      <th>duration_cat_1525-1555</th>\n",
       "      <th>duration_cat_1555-1585</th>\n",
       "      <th>duration_cat_1585-1615</th>\n",
       "      <th>duration_cat_1615-1645</th>\n",
       "      <th>duration_cat_1645-1675</th>\n",
       "      <th>duration_cat_1675-1705</th>\n",
       "      <th>duration_cat_1705-1735</th>\n",
       "      <th>duration_cat_1735-1765</th>\n",
       "      <th>duration_cat_175-205</th>\n",
       "      <th>duration_cat_1765-1795</th>\n",
       "      <th>duration_cat_1795-1825</th>\n",
       "      <th>duration_cat_1825-1855</th>\n",
       "      <th>duration_cat_1855-1885</th>\n",
       "      <th>duration_cat_1885-1915</th>\n",
       "      <th>duration_cat_1915-1945</th>\n",
       "      <th>duration_cat_1945-1975</th>\n",
       "      <th>duration_cat_1975-2005</th>\n",
       "      <th>duration_cat_2005-2035</th>\n",
       "      <th>duration_cat_2035-2065</th>\n",
       "      <th>duration_cat_205-235</th>\n",
       "      <th>duration_cat_2065-2095</th>\n",
       "      <th>duration_cat_2095-2125</th>\n",
       "      <th>duration_cat_2125-2155</th>\n",
       "      <th>duration_cat_2155-2185</th>\n",
       "      <th>duration_cat_2185-2215</th>\n",
       "      <th>duration_cat_2215-2245</th>\n",
       "      <th>duration_cat_2245-2275</th>\n",
       "      <th>duration_cat_2275-2305</th>\n",
       "      <th>duration_cat_2305-2335</th>\n",
       "      <th>duration_cat_2335-2365</th>\n",
       "      <th>duration_cat_235-265</th>\n",
       "      <th>duration_cat_2365-2395</th>\n",
       "      <th>duration_cat_2395-2425</th>\n",
       "      <th>duration_cat_2425-2455</th>\n",
       "      <th>duration_cat_2455-2485</th>\n",
       "      <th>duration_cat_2485-2515</th>\n",
       "      <th>duration_cat_25-55</th>\n",
       "      <th>duration_cat_2515-2545</th>\n",
       "      <th>duration_cat_2545-2575</th>\n",
       "      <th>duration_cat_2575-2605</th>\n",
       "      <th>duration_cat_2605-2635</th>\n",
       "      <th>duration_cat_2635-2665</th>\n",
       "      <th>duration_cat_265-295</th>\n",
       "      <th>duration_cat_2665-2695</th>\n",
       "      <th>duration_cat_2695-2725</th>\n",
       "      <th>duration_cat_2725-2755</th>\n",
       "      <th>duration_cat_2755-2785</th>\n",
       "      <th>duration_cat_2785-2815</th>\n",
       "      <th>duration_cat_2815-2845</th>\n",
       "      <th>duration_cat_2845-2875</th>\n",
       "      <th>duration_cat_2875-2905</th>\n",
       "      <th>duration_cat_2905-2935</th>\n",
       "      <th>duration_cat_2935-2965</th>\n",
       "      <th>duration_cat_295-325</th>\n",
       "      <th>duration_cat_2965-2995</th>\n",
       "      <th>duration_cat_2995-3025</th>\n",
       "      <th>duration_cat_3025-3055</th>\n",
       "      <th>duration_cat_3055-3085</th>\n",
       "      <th>duration_cat_3085-3115</th>\n",
       "      <th>duration_cat_3115-3145</th>\n",
       "      <th>duration_cat_3145-3175</th>\n",
       "      <th>duration_cat_3175-3205</th>\n",
       "      <th>duration_cat_3205-3235</th>\n",
       "      <th>duration_cat_3235-3265</th>\n",
       "      <th>duration_cat_325-355</th>\n",
       "      <th>duration_cat_3265-3295</th>\n",
       "      <th>duration_cat_3295-3325</th>\n",
       "      <th>duration_cat_3325-3355</th>\n",
       "      <th>duration_cat_3355-3385</th>\n",
       "      <th>duration_cat_3385-3415</th>\n",
       "      <th>duration_cat_3415-3445</th>\n",
       "      <th>duration_cat_3445-3475</th>\n",
       "      <th>duration_cat_3475-3505</th>\n",
       "      <th>duration_cat_3505-3535</th>\n",
       "      <th>duration_cat_3535-3565</th>\n",
       "      <th>duration_cat_355-385</th>\n",
       "      <th>duration_cat_3565-3595</th>\n",
       "      <th>duration_cat_3595-3625</th>\n",
       "      <th>duration_cat_3625-3655</th>\n",
       "      <th>duration_cat_3655-3685</th>\n",
       "      <th>duration_cat_3685-3715</th>\n",
       "      <th>duration_cat_3715-3745</th>\n",
       "      <th>duration_cat_3745-3775</th>\n",
       "      <th>duration_cat_3775-3805</th>\n",
       "      <th>duration_cat_3805-3835</th>\n",
       "      <th>duration_cat_3835-3865</th>\n",
       "      <th>duration_cat_385-415</th>\n",
       "      <th>duration_cat_3865-3895</th>\n",
       "      <th>duration_cat_3895-3925</th>\n",
       "      <th>duration_cat_3925-3955</th>\n",
       "      <th>duration_cat_415-445</th>\n",
       "      <th>duration_cat_445-475</th>\n",
       "      <th>duration_cat_475-505</th>\n",
       "      <th>duration_cat_505-535</th>\n",
       "      <th>duration_cat_535-565</th>\n",
       "      <th>duration_cat_55-85</th>\n",
       "      <th>duration_cat_565-595</th>\n",
       "      <th>duration_cat_595-625</th>\n",
       "      <th>duration_cat_625-655</th>\n",
       "      <th>duration_cat_655-685</th>\n",
       "      <th>duration_cat_685-715</th>\n",
       "      <th>duration_cat_715-745</th>\n",
       "      <th>duration_cat_745-775</th>\n",
       "      <th>duration_cat_775-805</th>\n",
       "      <th>duration_cat_805-835</th>\n",
       "      <th>duration_cat_835-865</th>\n",
       "      <th>duration_cat_85-115</th>\n",
       "      <th>duration_cat_865-895</th>\n",
       "      <th>duration_cat_895-925</th>\n",
       "      <th>duration_cat_925-955</th>\n",
       "      <th>duration_cat_955-985</th>\n",
       "      <th>duration_cat_985-1015</th>\n",
       "      <th>month_apr</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>346</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_cat_Adult  age_cat_Old Adult  age_cat_Senior  age_cat_YoungAdult  \\\n",
       "0              1                  0               0                   0   \n",
       "1              1                  0               0                   0   \n",
       "\n",
       "   cons.conf.idx  duration  duration_cat_-5-25  duration_cat_0--5  \\\n",
       "0          -46.2       487                   0                  0   \n",
       "1          -36.4       346                   0                  0   \n",
       "\n",
       "   duration_cat_1015-1045  duration_cat_1045-1075  duration_cat_1075-1105  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1105-1135  duration_cat_1135-1165  duration_cat_115-145  \\\n",
       "0                       0                       0                     0   \n",
       "1                       0                       0                     0   \n",
       "\n",
       "   duration_cat_1165-1195  duration_cat_1195-1225  duration_cat_1225-1255  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1255-1285  duration_cat_1285-1315  duration_cat_1315-1345  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1345-1375  duration_cat_1375-1405  duration_cat_1405-1435  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1435-1465  duration_cat_145-175  duration_cat_1465-1495  \\\n",
       "0                       0                     0                       0   \n",
       "1                       0                     0                       0   \n",
       "\n",
       "   duration_cat_1495-1525  duration_cat_1525-1555  duration_cat_1555-1585  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1585-1615  duration_cat_1615-1645  duration_cat_1645-1675  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1675-1705  duration_cat_1705-1735  duration_cat_1735-1765  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_175-205  duration_cat_1765-1795  duration_cat_1795-1825  \\\n",
       "0                     0                       0                       0   \n",
       "1                     0                       0                       0   \n",
       "\n",
       "   duration_cat_1825-1855  duration_cat_1855-1885  duration_cat_1885-1915  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_1915-1945  duration_cat_1945-1975  duration_cat_1975-2005  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_2005-2035  duration_cat_2035-2065  duration_cat_205-235  \\\n",
       "0                       0                       0                     0   \n",
       "1                       0                       0                     0   \n",
       "\n",
       "   duration_cat_2065-2095  duration_cat_2095-2125  duration_cat_2125-2155  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_2155-2185  duration_cat_2185-2215  duration_cat_2215-2245  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_2245-2275  duration_cat_2275-2305  duration_cat_2305-2335  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_2335-2365  duration_cat_235-265  duration_cat_2365-2395  \\\n",
       "0                       0                     0                       0   \n",
       "1                       0                     0                       0   \n",
       "\n",
       "   duration_cat_2395-2425  duration_cat_2425-2455  duration_cat_2455-2485  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_2485-2515  duration_cat_25-55  duration_cat_2515-2545  \\\n",
       "0                       0                   0                       0   \n",
       "1                       0                   0                       0   \n",
       "\n",
       "   duration_cat_2545-2575  duration_cat_2575-2605  duration_cat_2605-2635  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_2635-2665  duration_cat_265-295  duration_cat_2665-2695  \\\n",
       "0                       0                     0                       0   \n",
       "1                       0                     0                       0   \n",
       "\n",
       "   duration_cat_2695-2725  duration_cat_2725-2755  duration_cat_2755-2785  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_2785-2815  duration_cat_2815-2845  duration_cat_2845-2875  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_2875-2905  duration_cat_2905-2935  duration_cat_2935-2965  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_295-325  duration_cat_2965-2995  duration_cat_2995-3025  \\\n",
       "0                     0                       0                       0   \n",
       "1                     1                       0                       0   \n",
       "\n",
       "   duration_cat_3025-3055  duration_cat_3055-3085  duration_cat_3085-3115  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3115-3145  duration_cat_3145-3175  duration_cat_3175-3205  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3205-3235  duration_cat_3235-3265  duration_cat_325-355  \\\n",
       "0                       0                       0                     0   \n",
       "1                       0                       0                     0   \n",
       "\n",
       "   duration_cat_3265-3295  duration_cat_3295-3325  duration_cat_3325-3355  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3355-3385  duration_cat_3385-3415  duration_cat_3415-3445  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3445-3475  duration_cat_3475-3505  duration_cat_3505-3535  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3535-3565  duration_cat_355-385  duration_cat_3565-3595  \\\n",
       "0                       0                     0                       0   \n",
       "1                       0                     0                       0   \n",
       "\n",
       "   duration_cat_3595-3625  duration_cat_3625-3655  duration_cat_3655-3685  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3685-3715  duration_cat_3715-3745  duration_cat_3745-3775  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_3775-3805  duration_cat_3805-3835  duration_cat_3835-3865  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "\n",
       "   duration_cat_385-415  duration_cat_3865-3895  duration_cat_3895-3925  \\\n",
       "0                     0                       0                       0   \n",
       "1                     0                       0                       0   \n",
       "\n",
       "   duration_cat_3925-3955  duration_cat_415-445  duration_cat_445-475  \\\n",
       "0                       0                     0                     1   \n",
       "1                       0                     0                     0   \n",
       "\n",
       "   duration_cat_475-505  duration_cat_505-535  duration_cat_535-565  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "\n",
       "   duration_cat_55-85  duration_cat_565-595  duration_cat_595-625  \\\n",
       "0                   0                     0                     0   \n",
       "1                   0                     0                     0   \n",
       "\n",
       "   duration_cat_625-655  duration_cat_655-685  duration_cat_685-715  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "\n",
       "   duration_cat_715-745  duration_cat_745-775  duration_cat_775-805  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "\n",
       "   duration_cat_805-835  duration_cat_835-865  duration_cat_85-115  \\\n",
       "0                     0                     0                    0   \n",
       "1                     0                     0                    0   \n",
       "\n",
       "   duration_cat_865-895  duration_cat_895-925  duration_cat_925-955  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "\n",
       "   duration_cat_955-985  duration_cat_985-1015  month_apr  month_aug  \\\n",
       "0                     0                      0          0          0   \n",
       "1                     0                      0          0          0   \n",
       "\n",
       "   month_dec  month_jul  month_jun  month_mar  month_may  month_nov  \\\n",
       "0          0          0          0          0          1          0   \n",
       "1          0          0          0          0          1          0   \n",
       "\n",
       "   month_oct  month_sep  pdays  poutcome_failure  poutcome_nonexistent  \\\n",
       "0          0          0    999                 0                     1   \n",
       "1          0          0    999                 0                     1   \n",
       "\n",
       "   poutcome_success  previous  y  \n",
       "0                 0         0  0  \n",
       "1                 0         0  0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final training set\n",
    "trainset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ........ END PRE_PREPROCESSING ........"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set after pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 155)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 154)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape of training and testset\n",
    "if(trainset.shape[1]-1 != testset.shape[1]):\n",
    "    print('/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\')\n",
    "    print('/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\')\n",
    "    print('/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\ STOP /!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\')\n",
    "    print('/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\')\n",
    "    print('/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\/!\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing training + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get y column and delet it from training\n",
    "trainY = trainset['y']\n",
    "deleteColumns(['y'], trainset)\n",
    "trainX = trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# transform training into matrix (dataframe.as_matrix())\n",
    "np.random.seed(0)\n",
    "trainX = trainX.as_matrix()\n",
    "indices = np.random.permutation(len(trainX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code will be useless only for evaluating kappa and matthews\n",
    "# but we will train on all data set\n",
    "\n",
    "ind = 500\n",
    "X_train = trainX[indices[:-ind]]\n",
    "y_train = trainY[indices[:-ind]]\n",
    "X_test = trainX[indices[-ind:]]\n",
    "y_test = trainY[indices[-ind:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers & Cross validation\n",
    "The classifiers result + explanation why they have been used for Kaggle submissions:\n",
    "</br>\n",
    "\n",
    "In this part you will find the classifiers tested.\n",
    "But some of them have never been published into Kaggle.\n",
    "The most used are Random Forest (RF), Logistic Regression (LR) and the last one Ada Boost (ADA).\n",
    "</br>\n",
    "SVM have been used only for first prediction, but this one was bad.\n",
    "</br>\n",
    "So I invest myself into first Random Forest, I get better result but was not as accurate as what I have today.\n",
    "I tried to touch the parameters as the depth and so on, without good result.\n",
    "I switched to Logistic Regression (used in 98% of submissions) with balanced parameter.\n",
    "Logistic regression has an ability to handle dichotomous, binary data set, that's why I used it. But the issue,\n",
    "is that prediction were to much varying. we can pass from 270 to 290 to 230 predictions by changing few values from\n",
    "small changes. It was to hard to predict.\n",
    "The best I can had was 0.55090 and 0.58117 with Logistic regression\n",
    "</br>\n",
    "\n",
    "For the very last submission I switched to Ada Boost, to train weak learners (here decision trees) into strong ones.\n",
    "Regarding our unbalanced data, a weak classifier does not mean he his bad. That's why I tried to use it.\n",
    "\n",
    "Future works is improving it by using sample_weight parameter in fit function and give him some parameters.\n",
    "\n",
    "</br>\n",
    "Results of matthew, using 500 rows of our training set are in the bottom of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# cross validation parameter\n",
    "crv = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - SVM\n",
    "Use for first submission, one of the lowest matthews result having is by SVM.\n",
    "Unfortunately I was not able to use it here in unblanced data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svmC = svm.SVC()\n",
    "svmC.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM: 0.90 (+/- 0.02)\n",
      "Score =  0.932310770257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.90365449,  0.91      ,  0.90666667,  0.90666667,  0.88333333,\n",
       "        0.90666667,  0.90333333,  0.90666667,  0.88294314,  0.89297659])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreSVM = cross_val_score(svmC,trainX,trainY,cv=crv)\n",
    "print(\"Accuracy of SVM: %0.2f (+/- %0.2f)\" % (scoreSVM.mean(), scoreSVM.std() * 2))\n",
    "print(\"Score = \", svmC.score(trainX, trainY))\n",
    "scoreSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(class_weight='balanced')\n",
    "sgd.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD: 0.71 (+/- 0.56)\n",
      "Score =  0.306768922974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.67109635,  0.22333333,  0.85      ,  0.88333333,  0.89333333,\n",
       "        0.11      ,  0.91333333,  0.89666667,  0.81605351,  0.82943144])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreSGD = cross_val_score(sgd, trainX, trainY, cv=10)\n",
    "print(\"Accuracy of SGD: %0.2f (+/- %0.2f)\" % (scoreSGD.mean(), scoreSGD.std() * 2))\n",
    "print(\"Score = \", sgd.score(trainX, trainY))\n",
    "scoreSGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=5, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=5, random_state=0, class_weight='balanced')\n",
    "rf.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RF: 0.81 (+/- 0.08)\n",
      "Score =  0.818272757586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.76079734,  0.83666667,  0.76333333,  0.80333333,  0.83666667,\n",
       "        0.83666667,  0.83333333,  0.84333333,  0.72909699,  0.84280936])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreRF = cross_val_score(rf,trainX,trainY,cv=crv)\n",
    "print(\"Accuracy of RF: %0.2f (+/- %0.2f)\" % (scoreRF.mean(), scoreRF.std() * 2))\n",
    "print(\"Score = \", rf.score(trainX, trainY))\n",
    "scoreRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# evaluate error of a specific knn\n",
    "def evaluate_error (knn, X_test, y_test):\n",
    "    #knn.predict(X_test)\n",
    "    error = 1/1.0 - accuracy_score(y_test, knn.predict(X_test))/1.0\n",
    "    return error\n",
    "\n",
    "# find the lowest error and one of the bestK\n",
    "def KNeighborsClassifierFunc (X_train, y_train, X_test, y_test):\n",
    "    minimum_error = 1.0\n",
    "    bestK = 0\n",
    "    for k in range(1,100):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        error = evaluate_error(knn, X_test, y_test)\n",
    "        #print(error)\n",
    "        if(error < minimum_error):\n",
    "            bestK = k\n",
    "            minimum_error = error\n",
    "    return bestK, minimum_error\n",
    "\n",
    "#bestK, minimum = KNeighborsClassifierFunc(X_train, y_train, X_test, y_test)\n",
    "#print(\"Best k = \", bestK, ' with an error of ', minimum)\n",
    "\n",
    "bestK = 8\n",
    "\n",
    "# KNN optimized\n",
    "knn = KNeighborsClassifier(n_neighbors=bestK)\n",
    "knn.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN Optimized: 0.91 (+/- 0.02)\n",
      "Score =  0.918306102034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.910299  ,  0.92      ,  0.90333333,  0.91666667,  0.89333333,\n",
       "        0.91333333,  0.90333333,  0.91333333,  0.89632107,  0.89632107])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreKNNO = cross_val_score(knn,trainX,trainY,cv=crv)\n",
    "print(\"Accuracy of KNN Optimized: %0.2f (+/- %0.2f)\" % (scoreKNNO.mean(), scoreKNNO.std() * 2))\n",
    "print(\"Score = \", knn.score(trainX, trainY))\n",
    "scoreKNNO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "grd = GradientBoostingClassifier(max_features='auto')\n",
    "grd.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD: 0.90 (+/- 0.03)\n",
      "Score =  0.938646215405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.910299  ,  0.92333333,  0.88333333,  0.90666667,  0.89      ,\n",
       "        0.92      ,  0.91333333,  0.91666667,  0.88294314,  0.89632107])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreGB = cross_val_score(grd, trainX, trainY, cv=10)\n",
    "\n",
    "print(\"Accuracy of SGD: %0.2f (+/- %0.2f)\" % (scoreGB.mean(), scoreGB.std() * 2))\n",
    "print(\"Score = \", grd.score(trainX, trainY))\n",
    "scoreGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', class_weight='balanced')\n",
    "lr.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RF: 0.83 (+/- 0.05)\n",
      "Score =  0.841280426809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.82059801,  0.87333333,  0.83      ,  0.82      ,  0.80666667,\n",
       "        0.86      ,  0.83333333,  0.86      ,  0.7826087 ,  0.83277592])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreLR = cross_val_score(lr,trainX,trainY,cv=crv)\n",
    "print(\"Accuracy of RF: %0.2f (+/- %0.2f)\" % (scoreLR.mean(), scoreLR.std() * 2))\n",
    "print(\"Score = \", lr.score(trainX, trainY))\n",
    "scoreLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# base_estimator=DecisionTreeClassifier(max_depth=2)\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD: 0.90 (+/- 0.03)\n",
      "Score =  0.918639546516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.910299  ,  0.91      ,  0.86333333,  0.89333333,  0.90666667,\n",
       "        0.91333333,  0.90666667,  0.91666667,  0.89966555,  0.89632107])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreADA = cross_val_score(ada, trainX, trainY, cv=10)\n",
    "print(\"Accuracy of SGD: %0.2f (+/- %0.2f)\" % (scoreADA.mean(), scoreADA.std() * 2))\n",
    "print(\"Score = \", ada.score(trainX, trainY))\n",
    "scoreADA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Number of subscription predicted : 279 on 1120\n",
      "Stochast.\n",
      "Number of subscription predicted : 939 on 1120\n",
      "Ada Boost\n",
      "Number of subscription predicted : 92 on 1120\n"
     ]
    }
   ],
   "source": [
    "# display how much time yes was predicted and return output\n",
    "def how_much_predict(classifier):\n",
    "    output_Y = classifier.predict(testset.as_matrix())\n",
    "    yes = 0\n",
    "    for prediction in output_Y:\n",
    "        if prediction == 1:\n",
    "            yes = yes + 1\n",
    "        if prediction.dtype != 'int64':\n",
    "            print(prediction)\n",
    "    \n",
    "    print('Number of subscription predicted : ' + str(yes) + ' on ' + str(len(output_Y)))\n",
    "    return output_Y\n",
    "\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "how_much_predict(lr)\n",
    "print(\"Stochast.\")\n",
    "# here we can notice sgd is not predicting well too much yes over no (939), we excpet a low matthew value\n",
    "# (see table below)\n",
    "how_much_predict(sgd)\n",
    "\n",
    "# ADA BOOST IS THE CHOOSEN ONE\n",
    "print(\"Ada Boost\")\n",
    "output_Y = how_much_predict(ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Kappa & Matthews correlation score with some part of training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kappa</th>\n",
       "      <th>matthews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRD</th>\n",
       "      <td>0.595777</td>\n",
       "      <td>0.621619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.530075</td>\n",
       "      <td>0.576651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA</th>\n",
       "      <td>0.516965</td>\n",
       "      <td>0.537058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.490394</td>\n",
       "      <td>0.527852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.448052</td>\n",
       "      <td>0.497615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.417098</td>\n",
       "      <td>0.461375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.061996</td>\n",
       "      <td>0.178856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        kappa  matthews\n",
       "GRD  0.595777  0.621619\n",
       "SVM  0.530075  0.576651\n",
       "ADA  0.516965  0.537058\n",
       "LR   0.490394  0.527852\n",
       "RF   0.448052  0.497615\n",
       "KNN  0.417098  0.461375\n",
       "SGD  0.061996  0.178856"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# generating matthews, kappa result into a table\n",
    "dico = dict()\n",
    "\n",
    "the_choosen = rf\n",
    "kappa = cohen_kappa_score(y_test,the_choosen.predict(X_test))\n",
    "matthews = matthews_corrcoef(y_test,the_choosen.predict(X_test))\n",
    "dico['RF'] = { 'kappa':kappa, 'matthews':matthews}\n",
    "\n",
    "the_choosen = knn\n",
    "kappa = cohen_kappa_score(y_test,the_choosen.predict(X_test))\n",
    "matthews = matthews_corrcoef(y_test,the_choosen.predict(X_test))\n",
    "dico['KNN'] = { 'kappa':kappa, 'matthews':matthews}\n",
    "\n",
    "the_choosen = svmC\n",
    "kappa = cohen_kappa_score(y_test,the_choosen.predict(X_test))\n",
    "matthews = matthews_corrcoef(y_test,the_choosen.predict(X_test))\n",
    "dico['SVM'] = { 'kappa':kappa, 'matthews':matthews}\n",
    "\n",
    "the_choosen = sgd\n",
    "kappa = cohen_kappa_score(y_test,the_choosen.predict(X_test))\n",
    "matthews = matthews_corrcoef(y_test,the_choosen.predict(X_test))\n",
    "dico['SGD'] = { 'kappa':kappa, 'matthews':matthews}\n",
    "\n",
    "the_choosen = grd\n",
    "kappa = cohen_kappa_score(y_test,the_choosen.predict(X_test))\n",
    "matthews = matthews_corrcoef(y_test,the_choosen.predict(X_test))\n",
    "dico['GRD'] = { 'kappa':kappa, 'matthews':matthews}\n",
    "\n",
    "the_choosen = ada\n",
    "kappa = cohen_kappa_score(y_test,the_choosen.predict(X_test))\n",
    "matthews = matthews_corrcoef(y_test,the_choosen.predict(X_test))\n",
    "dico['ADA'] = { 'kappa':kappa, 'matthews':matthews}\n",
    "\n",
    "the_choosen = lr\n",
    "kappa = cohen_kappa_score(y_test,the_choosen.predict(X_test))\n",
    "matthews = matthews_corrcoef(y_test,the_choosen.predict(X_test))\n",
    "dico['LR'] = { 'kappa':kappa, 'matthews':matthews}\n",
    "\n",
    "result = pand.DataFrame({\n",
    "    'kappa':{\n",
    "        'RF':dico['RF'].get('kappa'),\n",
    "        'KNN':dico['KNN'].get('kappa'),\n",
    "        'SVM':dico['SVM'].get('kappa'),\n",
    "        'SGD':dico['SGD'].get('kappa'),\n",
    "        'GRD':dico['GRD'].get('kappa'),\n",
    "        'ADA':dico['ADA'].get('kappa'),\n",
    "        'LR':dico['LR'].get('kappa'),\n",
    "    },\n",
    "    'matthews':{\n",
    "        'RF':dico['RF'].get('matthews'),\n",
    "        'KNN':dico['KNN'].get('matthews'),\n",
    "        'SVM':dico['SVM'].get('matthews'),\n",
    "        'SGD':dico['SGD'].get('matthews'),\n",
    "        'GRD':dico['GRD'].get('matthews'),\n",
    "        'ADA':dico['ADA'].get('matthews'),\n",
    "        'LR':dico['LR'].get('matthews'),\n",
    "    }\n",
    "})\n",
    "\n",
    "result.sort_values(by=['matthews'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end I decided to use ADA, SVM and GRD were ignored because giving bad result in general (SVM first submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output result into a file\n",
    "client_ids = range(1, len(output_Y)+1)\n",
    "\n",
    "submission_Kaggle_df = {\n",
    "    'prediction':output_Y\n",
    "}\n",
    "\n",
    "submission_Kaggle = pand.DataFrame(submission_Kaggle_df)\n",
    "submission_Kaggle.index = np.arange(1, len(output_Y)+1)\n",
    "submission_Kaggle.to_csv('data/subKaggle_MESSAOUDI_Amin.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
